<!doctype html>
<html lang="en">
  <head>
    <!-- Required meta tags -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <!-- Bootstrap CSS -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.1.0/dist/css/bootstrap.min.css" rel="stylesheet">
    <link href="https://unpkg.com/tailwindcss@^2/dist/tailwind.min.css" rel="stylesheet">

    <title>Performance Metrics</title>
    <style>
      .metrics-section {
        margin-bottom: 30px;
      }
      .metrics-container {
        display: flex;
        justify-content: space-between;
        align-items: flex-start;
        gap: 20px;
      }
      .metrics-item {
        flex: 1;
        text-align: center;
      }
      .metrics-item img {
        display: block;
        margin: 0 auto;
        max-width: 100%;
        height: auto;
        margin-bottom: 10px;
      }
      .metrics-item p {
        font-size: 14px;
        text-align: left;
      }
    </style>
  </head>
  <body class="bg-gray-200">
    <header class="text-gray-600 body-font">
        <div class="container mx-auto flex flex-wrap p-5 flex-col md:flex-row items-center">
          <a class="flex title-font font-medium items-center text-gray-900 mb-4 md:mb-0">
            <svg xmlns="http://www.w3.org/2000/svg" fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" class="w-10 h-10 text-white p-2 bg-green-500 rounded-full" viewBox="0 0 24 24">
              <path d="M12 2L2 7l10 5 10-5-10-5zM2 17l10 5 10-5M2 12l10 5 10-5"></path>
            </svg>
            <span class="ml-3 text-xl">FAKE NEWS DETECTION</span>
          </a>
          <nav style="position: relative; bottom: 13px; left:100px;" class="md:ml-auto flex flex-wrap items-center text-base justify-center">
            <a href="{{ url_for('home') }}" class="mr-5 hover:text-gray-900">Prediction</a>
            <a href="{{ url_for('metrics') }}" class="mr-5 hover:text-gray-900">Performance Metrics</a>
            <a href="{{ url_for('faqs') }}" class="mr-5 hover:text-gray-900">FAQs</a>
            <a href="{{ url_for('contact') }}" class="mr-5 hover:text-gray-900">Contact Us</a>            
          </nav>
        </div>
      </header>
      <hr>
      <section class="text-gray-600 body-font">
        <div class="container px-5 py-24 mx-auto">
          <div class="flex flex-col text-center w-full mb-20">
            <h2 style="font-size:small;" class="text-xs text-green-500 tracking-widest font-medium title-font mb-1">THESIS PROJECT</h2>
            <h1 class="sm:text-3xl text-2xl font-medium title-font mb-4 text-gray-900">Performance Metrics</h1>
            <p class="lg:w-2/3 mx-auto leading-relaxed text-base">Here are the notable metrics for our Fake News Detection Model, including Confusion Matrics, Performance Table and ROC Curve.</p>
          </div>

          <div class="metrics-container">
            <div class="metrics-item">
              <h2 class="text-xl font-medium mb-2">Confusion Matrix</h2>
              <p class="mb-4">The confusion matrix provides an analysis of the classification model's performance, detailing the distribution of predictions for the two classes, "Fake" and "Real." The model successfully classified 17,544 instances of "Fake" and 17,361 instances of "Real," demonstrating its ability to make accurate predictions for both classes. However, it also made some misclassifications, labeling 1,356 "Fake" samples as "Real" and 1,690 "Real" samples as "Fake." This evaluation highlights the model's strengths and weaknesses, offering insights into its precision, recall, and overall effectiveness in distinguishing between the two classes.
</p>
              <img src="images/ConfusionMatrix.png" alt="Confusion Matrix">
            </div>
            <div class="metrics-item">
              <h2 class="text-xl font-medium mb-2">Performance Table</h2>
              <p class="mb-4">The performance metrics table summarizes the classification model's effectiveness using key evaluation metrics: precision, recall, and F1-score. For the "Fake" class (label 0), the model achieved a precision of 0.91, a recall of 0.93, and an F1-score of 0.92. For the "Real" class (label 1), the precision was 0.93, the recall was 0.91, and the F1-score was 0.92. The overall accuracy of the model stands at 0.92, while the weighted average precision, recall, and F1-score also equal 0.92, reflecting balanced and consistent performance across both classes.
</p>
              <img src="images/PerformanceMetrics.png" alt="Performance Table">
            </div>
            <div class="metrics-item">
              <h2 class="text-xl font-medium mb-2">ROC Curve</h2>
              <p class="mb-4">The Receiver Operating Characteristic (ROC) curve illustrates the performance of the classification model in distinguishing between the two classes. The curve plots the true positive rate (sensitivity) against the false positive rate, showing the trade-offs between these metrics. The area under the ROC curve (AUC) is 0.97, indicating that the model has excellent discriminatory power. The closer the curve is to the top-left corner, the better the model performs. The high AUC value reflects the model's ability to correctly classify samples with minimal false positives and negatives.


Together, these evaluation techniques provide a comprehensive analysis of the modelâ€™s strengths and weaknesses in detecting fake news, ensuring a reliable assessment of its predictive capabilities.</p>
              <img src="images/ROCCurve.png" alt="ROC Curve">
            </div>
          </div>

          <div class="text-center mt-4">
            <a href="{{ url_for('contact') }}" class="btn btn-warning">Want the Source Code? Contact us!</a>
          </div>
        </div>
      </section>
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.1.0/dist/js/bootstrap.bundle.min.js"></script>
  </body>
</html>

