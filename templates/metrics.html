<!doctype html>
<html lang="en">
  <head>
    <!-- Required meta tags -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <!-- Bootstrap CSS -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.1.0/dist/css/bootstrap.min.css" rel="stylesheet">
    <link href="https://unpkg.com/tailwindcss@^2/dist/tailwind.min.css" rel="stylesheet">

    <title>Performance Metrics</title>
    <style>
      .metrics-section {
        margin-bottom: 30px;
      }
      .metrics-container {
        display: flex;
        justify-content: space-between;
        align-items: flex-start;
        gap: 20px;
      }
      .metrics-item {
        flex: 1;
        text-align: center;
      }
      .metrics-item img {
        display: block;
        margin: 0 auto;
        max-width: 100%;
        height: auto;
        margin-bottom: 10px;
      }
      .metrics-item p {
        font-size: 14px;
        text-align: left;
      }
    </style>
  </head>
  <body class="bg-gray-200">
    <header class="text-gray-600 body-font">
        <div class="container mx-auto flex flex-wrap p-5 flex-col md:flex-row items-center">
          <a class="flex title-font font-medium items-center text-gray-900 mb-4 md:mb-0">
            <svg xmlns="http://www.w3.org/2000/svg" fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" class="w-10 h-10 text-white p-2 bg-green-500 rounded-full" viewBox="0 0 24 24">
              <path d="M12 2L2 7l10 5 10-5-10-5zM2 17l10 5 10-5M2 12l10 5 10-5"></path>
            </svg>
            <span class="ml-3 text-xl">FAKE NEWS DETECTION</span>
          </a>
          <nav style="position: relative; bottom: 13px; left:100px;" class="md:ml-auto flex flex-wrap items-center text-base justify-center">
            <a href="{{ url_for('home') }}" class="mr-5 hover:text-gray-900">Prediction</a>
            <a href="{{ url_for('metrics') }}" class="mr-5 hover:text-gray-900">Performance Metrics</a>
            <a href="{{ url_for('faqs') }}" class="mr-5 hover:text-gray-900">FAQs</a>
            <a href="{{ url_for('contact') }}" class="mr-5 hover:text-gray-900">Contact Us</a>            
          </nav>
        </div>
      </header>
      <hr>
      <section class="text-gray-600 body-font">
        <div class="container px-5 py-24 mx-auto">
          <div class="flex flex-col text-center w-full mb-20">
            <h2 style="font-size:small;" class="text-xs text-green-500 tracking-widest font-medium title-font mb-1">THESIS PROJECT</h2>
            <h1 class="sm:text-3xl text-2xl font-medium title-font mb-4 text-gray-900">Performance Metrics</h1>
            <p class="lg:w-2/3 mx-auto leading-relaxed text-base">Here are the notable metrics for our Fake News Detection Model, including Confusion Matrics, Performance Table and ROC Curve.</p>
          </div>

          <div class="metrics-container">
            <div class="metrics-item">
              <h2 class="text-xl font-medium mb-2">Confusion Matrix</h2>
              <p class="mb-4">The Confusion Matrix provides a detailed breakdown of the model’s predictions by showing the number of correctly and incorrectly classified instances for both fake and real news. It consists of four components: True Negatives (TN), where fake news is correctly identified as fake; False Positives (FP), where fake news is incorrectly classified as real; False Negatives (FN), where real news is mistakenly classified as fake; and True Positives (TP), where real news is correctly identified. The matrix is visualized using a heatmap to help understand how well the model distinguishes between the two classes.</p>
              <img src="/images/ConfusionMatrix.png" alt="Confusion Matrix">
            </div>
            <div class="metrics-item">
              <h2 class="text-xl font-medium mb-2">Performance Table</h2>
              <p class="mb-4">The Performance Metrics such as Precision, Recall, F1-score, and Accuracy are computed to assess the model’s effectiveness. Precision measures how many of the predicted real news articles were actually real, ensuring that the model does not misclassify too many fake articles as real. Recall indicates how many actual real news articles were correctly identified, showing the model’s sensitivity to detecting real news. F1-score, which balances precision and recall, provides a more comprehensive assessment of the model's performance. Lastly, accuracy, which calculates the overall correctness of the model, is also reported. The results are formatted into a structured table for easy interpretation.</p>
              <img src="/images/PerformanceMetrics.png" alt="Performance Table">
            </div>
            <div class="metrics-item">
              <h2 class="text-xl font-medium mb-2">ROC Curve</h2>
              <p class="mb-4">To further evaluate the model’s ability to distinguish between real and fake news, the ROC (Receiver Operating Characteristic) Curve is plotted. The ROC curve graphically represents the trade-off between True Positive Rate (TPR) and False Positive Rate (FPR) at various classification thresholds. The Area Under the Curve (AUC) is also computed to quantify the model’s ability to separate real and fake news, with a higher AUC indicating a better-performing model. The visualization of the ROC curve helps assess how well the model generalizes across different classification thresholds.

Together, these evaluation techniques provide a comprehensive analysis of the model’s strengths and weaknesses in detecting fake news, ensuring a reliable assessment of its predictive capabilities.</p>
              <img src="/images/ROCCurve.png" alt="ROC Curve">
            </div>
          </div>

          <div class="text-center mt-4">
            <a href="{{ url_for('contact') }}" class="btn btn-warning">Want the Source Code? Contact us!</a>
          </div>
        </div>
      </section>
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.1.0/dist/js/bootstrap.bundle.min.js"></script>
  </body>
</html>

